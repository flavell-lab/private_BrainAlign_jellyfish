{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 15:41:22.741219: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-24 15:41:22.741266: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-24 15:41:22.742598: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, cv2\n",
    "import h5py\n",
    "import tifffile\n",
    "from tqdm import tqdm, trange\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from deepreg.predict import unwrapped_predict, normalize_batched_image\n",
    "from deepreg.model.layer import Warping\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "label_shape = (30, 3)\n",
    "irregular = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register a video in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = \"/storage/fs/store1/brian/swimming_videos_RFa/Folder_20250214153740_RFa/RIG_20250214_Experiment_01_0-1999.tif\"\n",
    "tiff_folder = \"/storage/fs/store1/brian/swimming_videos_RFa/Folder_20250214153740_RFa/\"\n",
    "out_folder = tiff_folder\n",
    "\n",
    "\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/long_first_jelly_again/save/ckpt-626\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/long_first_jelly_redo_DP/save/ckpt-396\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/long_first_jelly_redo_DP_real/save/ckpt-368\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/weights_shifted_2/save/ckpt-385\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/all_labs_flat-TOOMUCHNORM2/save/ckpt-29\"\n",
    "# checkpoint_path = \"~/store1/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/all_labs_flat-TOOMUCHNORM2/save/ckpt-29\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/karen/save/ckpt-6\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/karen/save/ckpt-254\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/all_labs_mvmt_bounded/save/ckpt-237\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/all_labs_mvmt_bounded_2/save/ckpt-35\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/all_labs_mvmt_bounded_4-bgfloor/save/ckpt-293\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/all_labs_mvmt_bounded_6-log/save/ckpt-26\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/all_labs_mvmt_bounded_9-sing/save/ckpt-490\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/RFa_1-nolab/save/ckpt-999\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/RFa_2-imgpad_nl/save/ckpt-240\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/RFa_3-minpad/save/ckpt-126\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/RFa_4-waymore/save/ckpt-1771\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/RFa_4-waymore/save/ckpt-536\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/RFa_5-dataug/save/ckpt-87\"\n",
    "# checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/RFa_6-dpda/save/ckpt-190\"\n",
    "checkpoint_path = \"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/demo_notebook/RFa_6.1-cont/save/ckpt-688\"\n",
    "\n",
    "output_video_path = \"/home/brian/data4/brian/PBnJ/out_vids/no_align.mp4\"\n",
    "log_dir = \"/home/brian/data4/brian/PBnJ/out_vids/logs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tifffile.imread(tiff_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2, 1200, 1200)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(len(inputs.shape) == 3):\n",
    "    irregular = False\n",
    "    inputs = inputs[:, np.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_shape = np.array((1024, 1024))\n",
    "# crop_shape = np.array((1080, 1080))\n",
    "\n",
    "crop_offset = (inputs.shape[2:] - crop_shape) / 2\n",
    "assert np.all(crop_offset == crop_offset.astype(int))\n",
    "crop_offset = crop_offset.astype(int)\n",
    "\n",
    "## Crop the images\n",
    "inputs_crop = inputs[:, :, crop_offset[0]:crop_offset[0] + crop_shape[0], crop_offset[1]:crop_offset[1] + crop_shape[1]]\n",
    "assert np.all(inputs_crop.shape[2:] == crop_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if irregular:\n",
    "    input_red = inputs_crop[:, 1, ...]\n",
    "    input_green = inputs_crop[:, 0, ...]\n",
    "else:\n",
    "    input_red = inputs_crop[:, 0, ...]\n",
    "    # input_green = inputs_crop[:, 1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed img saved\n"
     ]
    }
   ],
   "source": [
    "if 'batched_fixed_image' not in locals():\n",
    "    fixed_image_ARCHIVE = input_red[0] # So we don't have to reload stuff\n",
    "    batched_fixed_image = np.repeat(np.expand_dims(input_red[0], axis=0), batch_size, axis=0).astype(np.float32)\n",
    "    print(\"Fixed img saved\")\n",
    "else:\n",
    "    batched_fixed_image = np.repeat(np.expand_dims(fixed_image_ARCHIVE, axis=0), batch_size, axis=0).astype(np.float32)\n",
    "    print(\"Restored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/brian/notebooks/brian/PBrainAlign_and_Jelly/private_BrainAlignNet/scripts\")\n",
    "from register import set_GPU, register\n",
    "# set_GPU(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-24 16:25:09 | WARNING  | Log directory /home/brian/data4/brian/PBnJ/out_vids/logs exists already.\n",
      "2025-04-24 16:25:09 | WARNING  | Using customized configuration. The code might break if the config doesn't match the saved model.\n",
      "Built inputs.\n",
      "Built control points.\n",
      "Concatenated images.\n",
      "{'extract_levels': ListWrapper([0, 1, 2, 3]), 'name': 'local', 'num_channel_initial': 16}\n",
      "Built backbone.\n",
      "Built DDF.\n",
      "Built warping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [08:44<00:00,  2.10s/it]\n",
      "/home/brian/.conda/envs/PB/lib/python3.11/site-packages/tifffile/tifffile.py:1753: UserWarning: <tifffile.TiffWriter 'WARPED-BOTH_RIG…nt_01_0-1999.tif'> writing nonconformant BigTIFF ImageJ\n",
      "  warnings.warn(\n",
      "100%|██████████| 250/250 [07:58<00:00,  1.92s/it]\n",
      "/home/brian/.conda/envs/PB/lib/python3.11/site-packages/tifffile/tifffile.py:1753: UserWarning: <tifffile.TiffWriter 'WARPED-BOTH_RIG_…1_2000-3999.tif'> writing nonconformant BigTIFF ImageJ\n",
      "  warnings.warn(\n",
      "100%|██████████| 250/250 [08:01<00:00,  1.93s/it]\n",
      "/home/brian/.conda/envs/PB/lib/python3.11/site-packages/tifffile/tifffile.py:1753: UserWarning: <tifffile.TiffWriter 'WARPED-BOTH_RIG_…1_4000-5999.tif'> writing nonconformant BigTIFF ImageJ\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#### FIRST WE'RE GOING TO JUST TRY TO ALIGN TO A SINGLE FRAME\n",
    "## The first batch of good videos was aligned using ckpt-90, going to switch to 626\n",
    "\n",
    "log_dir = \"/home/brian/data4/brian/PBnJ/out_vids/logs\"\n",
    "\n",
    "config_path = os.path.join(checkpoint_path.split(\"/save\")[0], \"config.yaml\")\n",
    "model = None\n",
    "\n",
    "# max_frames = 400\n",
    "max_frames = 2000\n",
    "# max_frames = 1000\n",
    "# max_frames = 8\n",
    "# side_len = 1080\n",
    "side_len = 1024\n",
    "red_offset = 0\n",
    "\n",
    "red_chan = 1\n",
    "other_chan = (red_chan - 1) % inputs.shape[1]\n",
    "\n",
    "padding = np.array([[0,0],[0,0],[0,0],[1,1]])\n",
    "\n",
    "# batched_fixed_image_pad = np.pad(batched_fixed_image[..., np.newaxis], padding, \"constant\", constant_values=0)\n",
    "# batched_fixed_image = np.log2((batched_fixed_image - np.min(batched_fixed_image)) + 1, dtype=np.float32) #### TODO? Change sqrt?\n",
    "batched_fixed_image_pad = np.pad(batched_fixed_image[..., np.newaxis], padding, \"constant\", constant_values=np.min(batched_fixed_image))\n",
    "z_depth = 3\n",
    "# batched_fixed_image_pad = np.repeat(batched_fixed_image[..., np.newaxis], z_depth, axis=-1)\n",
    "\n",
    "warping = Warping(fixed_image_size=(side_len, side_len, 3), batch_size=batch_size)\n",
    "# warping = Warping(fixed_image_size=(side_len, side_len, 2), batch_size=batch_size, interpolation=\"nearest\")\n",
    "\n",
    "# files = [\"0-1999\"]\n",
    "files = [\"RIG_20250214_Experiment_01_0-1999.tif\", \"RIG_20250214_Experiment_01_2000-3999.tif\", \"RIG_20250214_Experiment_01_4000-5999.tif\"\n",
    "         ]\n",
    "for file in files:\n",
    "    inputs = tifffile.imread(os.path.join(tiff_folder, file))\n",
    "    inputs_crop = inputs[:, :, crop_offset[0]:crop_offset[0] + crop_shape[0], crop_offset[1]:crop_offset[1] + crop_shape[1]]\n",
    "    input_red = inputs_crop[:, red_chan, ...]\n",
    "    input_green = inputs_crop[:, other_chan, ...]\n",
    "    outs = np.zeros_like(inputs_crop)\n",
    "    for frame in trange(0, max_frames, batch_size):\n",
    "        if frame + batch_size > (max_frames):\n",
    "            frame = (max_frames) - batch_size\n",
    "\n",
    "        batched_moving_image = input_red[(frame - red_offset):(frame-red_offset)+batch_size].astype(np.float32)\n",
    "        # batched_moving_image = np.log2((batched_moving_image - np.min(batched_moving_image)) + 1, dtype=np.float32)\n",
    "        # batched_moving_image = np.pad(batched_moving_image[..., np.newaxis], padding, \"constant\", constant_values=0)\n",
    "        batched_moving_image = np.pad(batched_moving_image[..., np.newaxis], padding, \"constant\", constant_values=np.min(batched_moving_image))\n",
    "        # batched_moving_image = np.repeat(batched_moving_image[..., np.newaxis], z_depth, axis=-1)\n",
    "        \n",
    "        ddf_output, pred_fixed_image, model = unwrapped_predict(\n",
    "            batched_fixed_image_pad,\n",
    "            batched_moving_image,\n",
    "            log_dir,\n",
    "            label_shape,\n",
    "            label_shape,\n",
    "            model = model,\n",
    "            model_ckpt_path = checkpoint_path,\n",
    "            model_config_path = config_path,\n",
    "        )\n",
    "\n",
    "        gr_in = np.pad(input_green[(frame):(frame)+batch_size, ..., np.newaxis], padding, \"constant\", constant_values=0).astype(np.float32)\n",
    "        outs[frame:(frame) + batch_size, other_chan] = warping(inputs=[ddf_output, gr_in]).numpy()[..., 1]\n",
    "        \n",
    "        batched_moving_image = input_red[(frame - red_offset):(frame-red_offset)+batch_size].astype(np.float32)\n",
    "        batched_moving_image = np.pad(batched_moving_image[..., np.newaxis], padding, \"constant\", constant_values=0)\n",
    "        outs[frame:(frame) + batch_size, red_chan] = warping(inputs=[ddf_output, batched_moving_image]).numpy()[..., 1]\n",
    "        \n",
    "        # outs[frame:(frame) + batch_size] = pred_fixed_image[..., 1] * 100\n",
    "    # tifffile.imwrite(os.path.join(out_folder, \"RED_WARPED_\" + file), outs)\n",
    "\n",
    "    tifffile.imwrite(os.path.join(out_folder, \"WARPED-BOTH_\" + file), outs, imagej=True, bigtiff=True)\n",
    "    # break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
